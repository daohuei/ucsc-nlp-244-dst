{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68075cf5-6e8a-4b5c-a991-6b9f0f919946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    BartForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "from datasets import load_dataset, Split, Dataset\n",
    "\n",
    "from trainer.curriculum_trainer import CurriculumTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2d2b734-466c-4adf-b76a-8a335a03a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from data.dataset.data_augmentations import flatten_conversation, random_mask_beliefs\n",
    "from gpu import get_device\n",
    "from utils import print_stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b520987a-4e93-45f1-8e6f-81a110056293",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from data.dataset.tokenize import tokenizer, preprocess_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb71ddf6-25c8-452a-a944-c93dccaaebeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-fa91ae44cff1e0ff\n",
      "WARNING:datasets.builder:Reusing dataset multi_woz_dataset (/data/users/cting3/.cache/huggingface/datasets/multi_woz_dataset/default-fa91ae44cff1e0ff/0.0.0/f68a68638b040ca98e35780d893ba6dd439629d12a3b62bdda1ba2e3d7a88647)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5041b39c6104269b0c621cc100dfdb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /data/users/cting3/.cache/huggingface/datasets/multi_woz_dataset/default-fa91ae44cff1e0ff/0.0.0/f68a68638b040ca98e35780d893ba6dd439629d12a3b62bdda1ba2e3d7a88647/cache-a1c988fe37507e5f.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /data/users/cting3/.cache/huggingface/datasets/multi_woz_dataset/default-fa91ae44cff1e0ff/0.0.0/f68a68638b040ca98e35780d893ba6dd439629d12a3b62bdda1ba2e3d7a88647/cache-339ba30f507aa4aa.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /data/users/cting3/.cache/huggingface/datasets/multi_woz_dataset/default-fa91ae44cff1e0ff/0.0.0/f68a68638b040ca98e35780d893ba6dd439629d12a3b62bdda1ba2e3d7a88647/cache-aeb133aae4fea810.arrow\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datasets import Dataset, load_dataset, Split\n",
    "from data.dataset.data_augmentations import flatten_conversation\n",
    "\n",
    "data_dir = Path(\"resources/bart/\")\n",
    "\n",
    "data_files = {\n",
    "    Split.TRAIN: str((data_dir / \"train.history_belief\").absolute()),\n",
    "    Split.VALIDATION: str((data_dir / \"val.history_belief\").absolute()),\n",
    "    Split.TEST: str((data_dir / \"test.history_belief\").absolute()),\n",
    "}\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"data/dataset/multiwoz_dataset.py\", data_files=data_files\n",
    ")\n",
    "dataset = dataset.map(\n",
    "    flatten_conversation,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e80b303a-7df9-4ebb-bd4a-5de1d0248c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-05d16ab4b849ba43\n",
      "WARNING:datasets.builder:Reusing dataset json (/data/users/cting3/.cache/huggingface/datasets/json/default-05d16ab4b849ba43/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690c2b09616543ca9c2714a9ed67dd12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /data/users/cting3/.cache/huggingface/datasets/json/default-05d16ab4b849ba43/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-3ca63803f869ab75.arrow\n",
      "WARNING:datasets.builder:Using custom data configuration default-5b742c810b4beab1\n",
      "WARNING:datasets.builder:Reusing dataset json (/data/users/cting3/.cache/huggingface/datasets/json/default-5b742c810b4beab1/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7eb007f45ba4f12b4a9d4d033872a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /data/users/cting3/.cache/huggingface/datasets/json/default-5b742c810b4beab1/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-21e8ae2a6cc37467.arrow\n"
     ]
    }
   ],
   "source": [
    "\n",
    "masked_beliefs_final_dev = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"resources/tokens/masked_beliefs_final_dev_token.json\",\n",
    ").map(preprocess_func, batched=True)[\"train\"]\n",
    "\n",
    "masked_beliefs_final_test = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"resources/tokens/masked_beliefs_final_test_token.json\",\n",
    ").map(preprocess_func, batched=True)[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f777b4aa-d2af-4c2d-a203-6ee514f41498",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = masked_beliefs_final_dev[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db988674-7fdb-4d81-83e4-4db9c8669ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s><s> <|context|> <|user|> i need to book a hotel in the east that has 4 stars. <|endofcontext|> <|previousbelief|> attraction area not mentioned, attraction name not mentioned, attraction type not mentioned, hospital department not mentioned, hotel area not mentioned, hotel book day not mentioned, hotel book people not mentioned, hotel book stay not mentioned, hotel internet not mentioned, hotel name not mentioned, hotel parking not mentioned, hotel pricerange not mentioned, hotel stars not mentioned, hotel type not mentioned, restaurant area not mentioned, restaurant book day not mentioned, restaurant book people not mentioned, restaurant book time not mentioned, restaurant food not mentioned, restaurant name not mentioned, restaurant pricerange not mentioned, taxi arriveby not mentioned, taxi departure not mentioned, taxi destination not mentioned, taxi leaveat not mentioned, train arriveby not mentioned, train book people not mentioned, train day not mentioned, train departure not mentioned, train destination not mentioned, train leaveat not mentioned <|endofpreviousbelief|> <|belief|> attraction area<mask>, attraction name<mask>, attraction type<mask>, hospital department<mask>, hotel area<mask>, hotel book day<mask>, hotel book people<mask>, hotel book stay<mask>, hotel internet<mask>, hotel name<mask>, hotel parking<mask>, hotel pricerange<mask>, hotel stars<mask>, hotel type<mask>, restaurant area<mask>, restaurant book day<mask>, restaurant book people<mask>, restaurant book time<mask>, restaurant food<mask>, restaurant name<mask>, restaurant pricerange<mask>, taxi arriveby<mask>, taxi departure<mask>, taxi destination<mask>, taxi leaveat<mask>, train arriveby<mask>, train book people<mask>, train day<mask>, train departure<mask>, train destination<mask>, train leaveat<mask> <|endofbelief|> </s></s>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4744f51d-e599-46de-b060-edf7689f777d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-fa91ae44cff1e0ff\n",
      "WARNING:datasets.builder:Reusing dataset multi_woz_dataset (/data/users/cting3/.cache/huggingface/datasets/multi_woz_dataset/default-fa91ae44cff1e0ff/0.0.0/f68a68638b040ca98e35780d893ba6dd439629d12a3b62bdda1ba2e3d7a88647)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a27d422e2004cbcaee103b05c77c975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /data/users/cting3/.cache/huggingface/datasets/multi_woz_dataset/default-fa91ae44cff1e0ff/0.0.0/f68a68638b040ca98e35780d893ba6dd439629d12a3b62bdda1ba2e3d7a88647/cache-a1c988fe37507e5f.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /data/users/cting3/.cache/huggingface/datasets/multi_woz_dataset/default-fa91ae44cff1e0ff/0.0.0/f68a68638b040ca98e35780d893ba6dd439629d12a3b62bdda1ba2e3d7a88647/cache-339ba30f507aa4aa.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /data/users/cting3/.cache/huggingface/datasets/multi_woz_dataset/default-fa91ae44cff1e0ff/0.0.0/f68a68638b040ca98e35780d893ba6dd439629d12a3b62bdda1ba2e3d7a88647/cache-aeb133aae4fea810.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================Flattening Conversation======================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_dir = Path(\"resources/bart/\")\n",
    "\n",
    "data_files = {\n",
    "    Split.TRAIN: str((data_dir / \"train.history_belief\").absolute()),\n",
    "    Split.VALIDATION: str((data_dir / \"val.history_belief\").absolute()),\n",
    "    Split.TEST: str((data_dir / \"test.history_belief\").absolute()),\n",
    "}\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"data/dataset/multiwoz_dataset.py\", data_files=data_files\n",
    ")\n",
    "print_stage(\"Flattening Conversation\")\n",
    "dataset = dataset.map(\n",
    "    flatten_conversation,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "582878b4-8994-4419-a5c0-80a2d5432aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50273, 768)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(\n",
    "    \"facebook/bart-base\"\n",
    ")#.to(device)\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7f60a50-9378-4228-92ef-0de1adf323db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e9c3571-d2f0-47c8-a93a-d236ffd2697a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['input_ids', 'attention_mask', 'labels'],\n",
       "     num_rows: 7372\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['conversation_id', 'turn', 'turn_number'],\n",
       "     num_rows: 7372\n",
       " }))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dataset = Dataset.from_dict(masked_beliefs_final_test[:10])\n",
    "masked_beliefs_final_test, dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6d12c68-5509-42a5-9033-c9f043762640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> <|context|> <|user|> i would like a taxi from saint john s college to pizza hut fen ditton . <|endofcontext|> <|belief|> taxi leaveat not mentioned , taxi destination pizza hut fenditton , taxi departure saint johns college , taxi arriveby not mentioned <|endofbelief|> </s>'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"test\"][\"turn\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "faf1284b-a913-477d-989a-77d8a0dd801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02679dcb-70c8-4258-ba5c-7d869b5910c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import default_data_collator\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e094e45c-e35e-4bad-b4b5-38b93b17cefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "from postprocessing import postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "204b5fb1-79ee-4f6c-91a9-7f7124daa3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from utils.Constants import SLOT_VALS\n",
    "\n",
    "slot_template = {slot:\"\" for slot in SLOT_VALS}\n",
    "def get_slot_map(slot_triplet_str_list):\n",
    "    slot_map = slot_template.copy()\n",
    "    for slot_triplet_str in slot_triplet_str_list:\n",
    "        slot_triplets = slot_triplet_str.split()\n",
    "        key = slot_triplets[0] + \" \" + slot_triplets[1]\n",
    "        val = slot_triplets[2]\n",
    "        if key not in SLOT_VALS:\n",
    "            continue\n",
    "        slot_map[key] = val\n",
    "    return slot_map\n",
    "\n",
    "def get_unique_slot_map(preds, targets):\n",
    "    unique_slots = set()\n",
    "    pred_map = {}\n",
    "    target_map = {}\n",
    "    \n",
    "    for pred_str in preds:\n",
    "        triplet = pred_str.split()\n",
    "        key = triplet[0] + \" \" + triplet[1]\n",
    "        val = triplet[2]\n",
    "        pred_map[key] = val\n",
    "        unique_slots.add(key)\n",
    "    \n",
    "    for target_str in targets:\n",
    "        triplet = target_str.split()\n",
    "        key = triplet[0] + \" \" + triplet[1]\n",
    "        val = triplet[2]\n",
    "        target_map[key] = val\n",
    "        unique_slots.add(key)\n",
    "    \n",
    "    return unique_slots.copy(), pred_map.copy(), target_map.copy()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab15a382-8822-4972-a9ce-1956cdd0bd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dst import ignore_none, default_cleaning, IGNORE_TURNS_TYPE2\n",
    "\n",
    "def evaluate_dst(results):\n",
    "    num_turns = 0\n",
    "    joint_acc = 0\n",
    "    slot_acc = 0\n",
    "    r_slot_acc = 0\n",
    "\n",
    "    num_slots = len(SLOT_VALS)\n",
    "    num_r_slots = 0\n",
    "\n",
    "    clean_tokens = ['<s>', '</s>']\n",
    "\n",
    "    for dial in tqdm(results.keys()):\n",
    "        dialogue_pred = results[dial]['generated_turn_belief']\n",
    "        dialogue_target = results[dial]['target_turn_belief']\n",
    "\n",
    "        for turn_id, (turn_target, turn_pred) in enumerate(zip(dialogue_target, dialogue_pred)):\n",
    "\n",
    "            # clean\n",
    "            for bs in turn_pred:\n",
    "                if bs in clean_tokens + ['', ' '] or bs.split()[-1] == 'none':\n",
    "                    turn_pred.remove(bs)\n",
    "\n",
    "            new_turn_pred = []\n",
    "            for bs in turn_pred:\n",
    "                for tok in clean_tokens:\n",
    "                    bs = bs.replace(tok, '').strip()\n",
    "                    new_turn_pred.append(bs)\n",
    "            turn_pred = new_turn_pred\n",
    "\n",
    "            turn_pred, turn_target = ignore_none(turn_pred, turn_target)\n",
    "            turn_pred, turn_target = default_cleaning(turn_pred, turn_target)\n",
    "\n",
    "            join_flag = False\n",
    "\n",
    "            # calculate joint accuracy\n",
    "            if set(turn_target) == set(turn_pred):\n",
    "                joint_acc += 1\n",
    "                join_flag = True\n",
    "\n",
    "            pred_slot_map = get_slot_map(turn_pred)\n",
    "            target_slot_map = get_slot_map(turn_target)\n",
    "\n",
    "            # calculate slot accuracy\n",
    "            for slot_key in SLOT_VALS:\n",
    "                if target_slot_map[slot_key] == pred_slot_map[slot_key]:\n",
    "                    slot_acc += 1\n",
    "\n",
    "            # calculate relative slot accuracy\n",
    "            unique_slots, unique_pred_map, unique_target_map = get_unique_slot_map(turn_pred, turn_target)\n",
    "            for slot_key in unique_slots:\n",
    "                if slot_key not in unique_target_map.keys(): continue\n",
    "                if slot_key not in unique_pred_map.keys(): continue\n",
    "                if unique_target_map[slot_key] == unique_pred_map[slot_key]:\n",
    "                    r_slot_acc += 1\n",
    "            num_r_slots += len(unique_slots)\n",
    "\n",
    "            num_turns += 1\n",
    "\n",
    "    print('joint accuracy: {}'.format(joint_acc / num_turns))\n",
    "    print('slot accuracy: {}'.format(slot_acc / (num_slots * num_turns)))\n",
    "    print('relative slot accuracy: {}'.format(r_slot_acc / num_r_slots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8970cbb3-5f59-46d1-9c31-cda4ea0bf167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-3824aa86bde2>:2: FutureWarning: set_caching_enabled is deprecated and will be removed in the next major version of datasets. Use datasets.enable_caching() or datasets.disable_caching() instead. This function will be removed in a future version of datasets.\n",
      "  set_caching_enabled(False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe803fd1bca2464b942cfa594814732a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7372 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import set_caching_enabled\n",
    "set_caching_enabled(False)\n",
    "masked_beliefs_final_test = dataset[\"test\"].map(\n",
    "    lambda d: random_mask_beliefs(d, 1), remove_columns=\"turn\"\n",
    ")\n",
    "# masked_beliefs_final = masked_beliefs_final.map(\n",
    "#     tokenization,\n",
    "#     batched=True,\n",
    "#     remove_columns=masked_beliefs_final[\"train\"].column_names,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f402908-0f92-4fda-bd9e-8d7d37fa5916",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = masked_beliefs_final_test[\"masked\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1fac783-b099-4e34-ae2d-cd299e09dc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<s> <|context|> <|user|> i would like a taxi from saint john s college to pizza hut fen ditton . <|endofcontext|> <|previousbelief|> attraction area not mentioned , attraction name not mentioned , attraction type not mentioned , hospital department not mentioned , hotel area not mentioned , hotel book day not mentioned , hotel book people not mentioned , hotel book stay not mentioned , hotel internet not mentioned , hotel name not mentioned , hotel parking not mentioned , hotel pricerange not mentioned , hotel stars not mentioned , hotel type not mentioned , restaurant area not mentioned , restaurant book day not mentioned , restaurant book people not mentioned , restaurant book time not mentioned , restaurant food not mentioned , restaurant name not mentioned , restaurant pricerange not mentioned , taxi arriveby not mentioned , taxi departure not mentioned , taxi destination not mentioned , taxi leaveat not mentioned , train arriveby not mentioned , train book people not mentioned , train day not mentioned , train departure not mentioned , train destination not mentioned , train leaveat not mentioned <|endofpreviousbelief|> <|belief|> attraction area <mask> , attraction name <mask> , attraction type <mask> , hospital department <mask> , hotel area <mask> , hotel book day <mask> , hotel book people <mask> , hotel book stay <mask> , hotel internet <mask> , hotel name <mask> , hotel parking <mask> , hotel pricerange <mask> , hotel stars <mask> , hotel type <mask> , restaurant area <mask> , restaurant book day <mask> , restaurant book people <mask> , restaurant book time <mask> , restaurant food <mask> , restaurant name <mask> , restaurant pricerange <mask> , taxi arriveby <mask> , taxi departure <mask> , taxi destination <mask> , taxi leaveat <mask> , train arriveby <mask> , train book people <mask> , train day <mask> , train departure <mask> , train destination <mask> , train leaveat <mask> <|endofbelief|> </s>',\n",
       " '<s> <|context|> <|user|> i would like a taxi from saint john s college to pizza hut fen ditton . <|endofcontext|> <|previousbelief|> attraction area not mentioned , attraction name not mentioned , attraction type not mentioned , hospital department not mentioned , hotel area not mentioned , hotel book day not mentioned , hotel book people not mentioned , hotel book stay not mentioned , hotel internet not mentioned , hotel name not mentioned , hotel parking not mentioned , hotel pricerange not mentioned , hotel stars not mentioned , hotel type not mentioned , restaurant area not mentioned , restaurant book day not mentioned , restaurant book people not mentioned , restaurant book time not mentioned , restaurant food not mentioned , restaurant name not mentioned , restaurant pricerange not mentioned , taxi arriveby not mentioned , taxi departure not mentioned , taxi destination not mentioned , taxi leaveat not mentioned , train arriveby not mentioned , train book people not mentioned , train day not mentioned , train departure not mentioned , train destination not mentioned , train leaveat not mentioned <|endofpreviousbelief|> <|belief|> attraction area <mask> , attraction name <mask> , attraction type <mask> , hospital department <mask> , hotel area <mask> , hotel book day <mask> , hotel book people <mask> , hotel book stay <mask> , hotel internet <mask> , hotel name <mask> , hotel parking <mask> , hotel pricerange <mask> , hotel stars <mask> , hotel type <mask> , restaurant area <mask> , restaurant book day <mask> , restaurant book people <mask> , restaurant book time <mask> , restaurant food <mask> , restaurant name <mask> , restaurant pricerange <mask> , taxi arriveby <mask> , taxi departure <mask> , taxi destination <mask> , taxi leaveat <mask> , train arriveby <mask> , train book people <mask> , train day <mask> , train departure <mask> , train destination <mask> , train leaveat <mask> <|endofbelief|> </s>')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.dataset.multiwoz_dataset import HistoryBelief, parse_raw_belief\n",
    "HistoryBelief(sample).text, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3da357ed-c036-4362-b338-0fa17fdc26f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset.tokenize import tokenizer\n",
    "encoding = tokenizer(HistoryBelief(sample).text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "98ad6a13-0ca4-4a3a-ab98-beb7159624c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import (\n",
    "    default_data_collator,\n",
    "    BartForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1a4033f-a356-4a96-8add-8ae59186912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BartForConditionalGeneration.from_pretrained(\n",
    "        # \"facebook/bart-base\"\n",
    "        # \"checkpoints/bart_finetune_cur/final/checkpoint-14195\"\n",
    "        # \"checkpoints/bart_finetune/final/checkpoint-28390\"\n",
    "        \"checkpoints/bart_finetune_cur/course_4/checkpoint-14195\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6789452d-5bfd-4ec0-8589-67db7df83788",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    output = model(**encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6d3ed18b-ce3b-4056-a4c5-f84ce0d77292",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = output.logits.argmax(-1)\n",
    "prediction_texts = tokenizer.batch_decode(\n",
    "    generated_ids, skip_special_tokens=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8031b7ab-9ead-47df-98f0-68f96ae89c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s><s> <|context|> <|user|> i would like a taxi from saint john s college to pizza hut fen ditton. <|endofcontext|> <|belief|> taxraction type not mentioned <|endofbelief|>  train type saint mentioned, train area not mentioned, attraction department not mentioned, attraction name not mentioned, hotel parking day not mentioned, hotel parking stay none mentioned, hotel parking stay none mentioned, attraction type not mentioned, hotel type pizza mentioned, hotel type not mentioned, hotel pricerange not mentioned, hotel stars not mentioned, hotel type not mentioned, attraction book not mentioned <|endofbelief|>  attraction book day not mentioned, attraction book people none mentioned, attraction book time not mentioned, hotel book not mentioned, restaurant pr pizza mentioned, restaurant areaicerange not mentioned, restaurant departureby not mentioned <|endofbelief|>  attraction departure saint mentioned <|endofbelief|>  attraction arrive pizza mentioned, restaurant arriveat not mentioned, taxi destinationby not mentioned, train departure departure none mentioned, train departure not mentioned, train departure saint mentioned <|endofbelief|>  train book not mentioned <|endofbelief|>  train bookat not mentioned <|endofbelief|> </s>'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_texts[0][:prediction_texts[0].index(\"</s>\")] + \"</s>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b89d433-8794-4f23-859e-79745531aff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9a1f9e8a-fabe-4165-beee-2c66c245e3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "giu = HistoryBelief(prediction_texts[0][:prediction_texts[0].index(\"</s>\")] + \"</s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "963f5d46-d832-4125-a7f3-ff003808a7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('attraction area', 'not mentioned'),\n",
       "             ('attraction name', 'not mentioned'),\n",
       "             ('attraction type', 'not mentioned'),\n",
       "             ('hospital department', 'not mentioned'),\n",
       "             ('hotel area', 'not mentioned'),\n",
       "             ('hotel book day', 'not mentioned'),\n",
       "             ('hotel book people', 'not mentioned'),\n",
       "             ('hotel book stay', 'not mentioned'),\n",
       "             ('hotel internet', 'not mentioned'),\n",
       "             ('hotel name', 'not mentioned'),\n",
       "             ('hotel parking', 'stay none mentioned'),\n",
       "             ('hotel pricerange', 'not mentioned'),\n",
       "             ('hotel stars', 'not mentioned'),\n",
       "             ('hotel type', 'not mentioned'),\n",
       "             ('restaurant area', 'not mentioned'),\n",
       "             ('restaurant book day', 'not mentioned'),\n",
       "             ('restaurant book people', 'not mentioned'),\n",
       "             ('restaurant book time', 'not mentioned'),\n",
       "             ('restaurant food', 'not mentioned'),\n",
       "             ('restaurant name', 'not mentioned'),\n",
       "             ('restaurant pricerange', 'not mentioned'),\n",
       "             ('taxi arriveby', 'not mentioned'),\n",
       "             ('taxi departure', 'not mentioned'),\n",
       "             ('taxi destination', 'not mentioned'),\n",
       "             ('taxi leaveat', 'not mentioned'),\n",
       "             ('train arriveby', 'not mentioned'),\n",
       "             ('train book people', 'not mentioned'),\n",
       "             ('train day', 'not mentioned'),\n",
       "             ('train departure',\n",
       "              'saint mentioned <|endofbelief|>  train book not mentioned <|endofbelief|>  train bookat not mentioned'),\n",
       "             ('train destination', 'not mentioned'),\n",
       "             ('train leaveat', 'not mentioned'),\n",
       "             ('taxraction type',\n",
       "              'not mentioned <|endofbelief|>  train type saint mentioned'),\n",
       "             ('train area', 'not mentioned'),\n",
       "             ('attraction department', 'not mentioned'),\n",
       "             ('attraction book', 'time not mentioned'),\n",
       "             ('hotel book', 'not mentioned'),\n",
       "             ('restaurant pr', 'pizza mentioned'),\n",
       "             ('restaurant areaicerange', 'not mentioned'),\n",
       "             ('restaurant departureby',\n",
       "              'not mentioned <|endofbelief|>  attraction departure saint mentioned <|endofbelief|>  attraction arrive pizza mentioned'),\n",
       "             ('restaurant arriveat', 'not mentioned'),\n",
       "             ('taxi destinationby', 'not mentioned')])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "giu.belief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3bd83530-8f15-4d32-8708-4b599b546328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3954e8abf64236bb21571528885d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7372 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-19798d4883e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mgenerated_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py_3_8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py_3_8/lib/python3.8/site-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1363\u001b[0m                 )\n\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1366\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py_3_8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py_3_8/lib/python3.8/site-packages/transformers/adapters/context.py\u001b[0m in \u001b[0;36mwrapper_func\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapters\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py_3_8/lib/python3.8/site-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1250\u001b[0m         )\n\u001b[1;32m   1251\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1253\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py_3_8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py_3_8/lib/python3.8/site-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1105\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py_3_8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py_3_8/lib/python3.8/site-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m             )\n\u001b[1;32m    456\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attention_adapters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_attn_layer_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;31m# add cross-attn to positions 3,4 of present_key_value tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py_3_8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py_3_8/lib/python3.8/site-packages/transformers/adapters/layer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor, layer_norm)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapter_layer_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py_3_8/lib/python3.8/site-packages/transformers/adapters/layer.py\u001b[0m in \u001b[0;36madapter_layer_forward\u001b[0;34m(self, hidden_states, input_tensor, layer_norm)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlayer_norm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "previous_belief_text = \"\"\n",
    "output_pred = []\n",
    "for idx in tqdm(range(len(masked_beliefs_final_test))):\n",
    "    masked_text = masked_beliefs_final_test[\"masked\"][idx]\n",
    "    history_belief = HistoryBelief(masked_text)\n",
    "    if masked_beliefs_final_test[\"turn_number\"][idx] != 1:\n",
    "        # update previous belief\n",
    "        history_belief.prev_belief = parse_raw_belief(previous_belief_text)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(**encoding)\n",
    "        \n",
    "    generated_ids = output.logits.argmax(-1)\n",
    "    prediction_texts = tokenizer.batch_decode(\n",
    "        generated_ids, skip_special_tokens=False\n",
    "    )\n",
    "    clean_pred_text = prediction_texts[0][:prediction_texts[0].index(\"</s>\")] + \"</s>\"\n",
    "    pred_hb = HistoryBelief(clean_pred_text)\n",
    "    previous_belief_text = pred_hb.belief_text\n",
    "    output_pred.append(pred_hb.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c67d4e24-1096-4e6e-9b76-bcdc00caf0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e797b7d12c4ba4be74be079797e866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dev_loader = DataLoader(\n",
    "            dataset=masked_beliefs_final_dev,\n",
    "            batch_size=4,\n",
    "            collate_fn=default_data_collator,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "model.eval()\n",
    "dev_results = {}\n",
    "predictions = []\n",
    "turn_id = 0\n",
    "for batch in tqdm(dev_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(**batch)\n",
    "    generated_ids = output.logits.argmax(-1)\n",
    "    prediction_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=False)\n",
    "    \n",
    "    for prediction_text in prediction_texts:\n",
    "        gold_text = dataset[\"validation\"][\"turn\"][turn_id]\n",
    "        \n",
    "        dialogue_id = dataset[\"validation\"][\"conversation_id\"][turn_id]\n",
    "        if dialogue_id not in dev_results.keys():\n",
    "            dev_results[dialogue_id] = {\n",
    "                'generated_turn_belief': [],\n",
    "                'target_turn_belief': [],\n",
    "            }\n",
    "        \n",
    "        dev_results[dialogue_id][\"generated_turn_belief\"] += [postprocessing(prediction_text)]\n",
    "        dev_results[dialogue_id][\"target_turn_belief\"] += [postprocessing(gold_text)]\n",
    "\n",
    "        turn_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6f83d0c5-6c3c-49e2-8b1f-91655fef0006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544ef95658b74e1f89cc26823a3268ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint accuracy: 0.0\n",
      "slot accuracy: 0.8032258064516129\n",
      "relative slot accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " {1: {'generated_turn_belief': [[], [], [], [], [], [], [], [], []],\n",
       "   'target_turn_belief': [['hotel area east ', 'hotel stars 4 '],\n",
       "    ['hotel area east ',\n",
       "     'hotel parking yes ',\n",
       "     'hotel stars 4 ',\n",
       "     'hotel internet yes '],\n",
       "    ['hotel name wartworth ',\n",
       "     'hotel area east ',\n",
       "     'hotel parking yes ',\n",
       "     'hotel stars 4 ',\n",
       "     'hotel internet yes '],\n",
       "    ['hotel name wartworth ',\n",
       "     'hotel area east ',\n",
       "     'hotel parking yes ',\n",
       "     'hotel stars 4 ',\n",
       "     'hotel internet yes ',\n",
       "     'hotel book people 1 ',\n",
       "     'hotel book day friday ',\n",
       "     'hotel book stay 1'],\n",
       "    ['hotel name wartworth ',\n",
       "     'hotel area east ',\n",
       "     'hotel parking yes ',\n",
       "     'hotel stars 4 ',\n",
       "     'hotel internet yes ',\n",
       "     'hotel book people 1 ',\n",
       "     'hotel book day friday ',\n",
       "     'hotel book stay 1 ',\n",
       "     'train destination bishops stortford ',\n",
       "     'train day friday ',\n",
       "     'train departure cambridge'],\n",
       "    ['hotel name wartworth ',\n",
       "     'hotel area east ',\n",
       "     'hotel parking yes ',\n",
       "     'hotel stars 4 ',\n",
       "     'hotel internet yes ',\n",
       "     'hotel book people 1 ',\n",
       "     'hotel book day friday ',\n",
       "     'hotel book stay 1 ',\n",
       "     'train destination bishops stortford ',\n",
       "     'train day friday ',\n",
       "     'train arriveby 19:45 ',\n",
       "     'train departure cambridge'],\n",
       "    ['hotel name wartworth ',\n",
       "     'hotel area east ',\n",
       "     'hotel parking yes ',\n",
       "     'hotel stars 4 ',\n",
       "     'hotel internet yes ',\n",
       "     'hotel book people 1 ',\n",
       "     'hotel book day friday ',\n",
       "     'hotel book stay 1 ',\n",
       "     'train destination bishops stortford ',\n",
       "     'train day friday ',\n",
       "     'train arriveby 19:45 ',\n",
       "     'train departure cambridge ',\n",
       "     'train book people 1'],\n",
       "    ['hotel name wartworth ',\n",
       "     'hotel area east ',\n",
       "     'hotel parking yes ',\n",
       "     'hotel stars 4 ',\n",
       "     'hotel internet yes ',\n",
       "     'hotel book people 3 ',\n",
       "     'hotel book day monday ',\n",
       "     'hotel book stay 4 ',\n",
       "     'train destination bishops stortford ',\n",
       "     'train day friday ',\n",
       "     'train arriveby 19:45 ',\n",
       "     'train departure cambridge ',\n",
       "     'train book people 1'],\n",
       "    ['hotel name wartworth ',\n",
       "     'hotel area east ',\n",
       "     'hotel parking yes ',\n",
       "     'hotel stars 4 ',\n",
       "     'hotel internet yes ',\n",
       "     'hotel book people 3 ',\n",
       "     'hotel book day monday ',\n",
       "     'hotel book stay 4 ',\n",
       "     'train destination bishops stortford ',\n",
       "     'train day friday ',\n",
       "     'train arriveby 19:45 ',\n",
       "     'train departure cambridge ',\n",
       "     'train book people 1']]},\n",
       "  2: {'generated_turn_belief': [[]],\n",
       "   'target_turn_belief': [['train destination cambridge ']]}})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_dst(dev_results), dev_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55566647-9c36-479e-8046-702e380484df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c66c45cd135484cb9001ea171b7c1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "test_loader = DataLoader(\n",
    "            dataset=masked_beliefs_final_test,\n",
    "            batch_size=4,\n",
    "            collate_fn=default_data_collator,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "model.eval()\n",
    "test_results = {}\n",
    "predictions = []\n",
    "turn_id = 0\n",
    "for batch in tqdm(test_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(**batch)\n",
    "    generated_ids = output.logits.argmax(-1)\n",
    "    prediction_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=False)\n",
    "    \n",
    "    for prediction_text in prediction_texts:\n",
    "        gold_text = dataset[\"test\"][\"turn\"][turn_id]\n",
    "        \n",
    "        dialogue_id = dataset[\"test\"][\"conversation_id\"][turn_id]\n",
    "        if dialogue_id not in test_results.keys():\n",
    "            test_results[dialogue_id] = {\n",
    "                'generated_turn_belief': [],\n",
    "                'target_turn_belief': [],\n",
    "            }\n",
    "        \n",
    "        test_results[dialogue_id][\"generated_turn_belief\"] += [postprocessing(prediction_text)]\n",
    "        test_results[dialogue_id][\"target_turn_belief\"] += [postprocessing(gold_text)]\n",
    "\n",
    "        turn_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "af8c589d-ca6c-439e-9446-57660187e847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0d630d3a424984af379ed920eeec84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint accuracy: 0.2\n",
      "slot accuracy: 0.9354838709677419\n",
      "relative slot accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " {1: {'generated_turn_belief': [[], [], [], []],\n",
       "   'target_turn_belief': [['taxi destination pizza hut fenditton ',\n",
       "     'taxi departure saint johns college '],\n",
       "    ['taxi leaveat 17:15 ',\n",
       "     'taxi destination pizza hut fenditton ',\n",
       "     'taxi departure saint johns college '],\n",
       "    ['taxi leaveat 17:15 ',\n",
       "     'taxi destination pizza hut fenditton ',\n",
       "     'taxi departure saint johns college '],\n",
       "    ['taxi leaveat 17:15 ',\n",
       "     'taxi destination pizza hut fenditton ',\n",
       "     'taxi departure saint johns college ']]},\n",
       "  2: {'generated_turn_belief': [[], [], [], [], [], []],\n",
       "   'target_turn_belief': [[],\n",
       "    [],\n",
       "    ['attraction name nusha '],\n",
       "    ['attraction name nusha '],\n",
       "    ['restaurant food indian ',\n",
       "     'restaurant area centre ',\n",
       "     'attraction name nusha '],\n",
       "    ['restaurant food indian ',\n",
       "     'restaurant pricerange expensive ',\n",
       "     'restaurant area centre ',\n",
       "     'attraction name nusha ']]}})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_dst(test_results), test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8f455a-038a-4de7-8cb4-7534eb25c64f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
